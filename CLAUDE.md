# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## What This Is

x-agent is a collection of Claude Code skills (prompt-based, not traditional code) for generating social media posts (X/Twitter + Threads) that match a specific user's voice. It uses a Twitter MCP server for API access.

## Architecture

This is a **skills-only repo** — no build system, no tests, no runtime code. The "code" is markdown-based skill definitions that Claude Code executes directly.

```
skills/          → Claude Code skill definitions (markdown with YAML frontmatter)
scripts/         → Utility scripts (tweet parsing, etc.)
examples/        → Example outputs showing expected formats
data/            → Runtime data directory (git-ignored)
  ├── config.json    → Twitter username, rest_id, RSS feeds
  ├── profile.md     → User persona & style rules (generated by /init)
  ├── tweets/        → Raw tweet archives (generated by /init)
  ├── ideas/         → Recorded ideas by week (generated by /idea)
  ├── research/      → Fetched research data (generated by /twitter)
  ├── posts/         → Generated posts (generated by /twitter)
  └── comments/      → Generated comments by date (generated by /comment)
```

## Skills

| Skill | File | Purpose |
|-------|------|---------|
| `/init "username"` | `skills/init.md` | Fetch Twitter user info + tweets → build persona profile → save to `./data/profile.md` and `./data/tweets/` |
| `/idea "text"` | `skills/idea.md` | Append a timestamped idea to `./data/ideas/YYYY-WXX.md` |
| `/twitter "topic"` | `skills/twitter.md` | Research topic → match user style from profile → generate X + Threads posts → save to `./data/posts/` |
| `/comment`, `/comment "topic"`, `/comment "@user"` | `skills/comment.md` | Find tweets worth commenting on → generate altruistic comments → save to `./data/comments/YYYY-MM-DD.md` |

## Key Design Decisions

- **All data lives in `./data/`** (git-ignored). The repo only contains skill definitions and examples.
- **Profile-first workflow**: `/init` must run before `/twitter` to establish the user's voice. The profile at `./data/profile.md` contains style rules that `/twitter` references.
- **Twitter MCP dependency**: Skills assume a Twitter MCP server is configured. The `Get User By Username` and `Search Twitter` (with `from:username` query) endpoints are the primary data sources. Note: `Get User Tweets` may fail due to large rest_id precision issues — use `Search Twitter` with `from:username` as a workaround.
- **Bilingual support**: Generated content defaults to English. The `/comment` skill matches the language of the original tweet.

## Skill File Format

Skills use YAML frontmatter + markdown body:

```yaml
---
name: skill-name
description: Short description. Usage: /skill-name "args"
user-invocable: true
---
```

`$ARGUMENTS` in the body is replaced with user-provided arguments at invocation time.

## Working with Twitter MCP

- User profile lookup: `Get_User_By_Username` → returns `rest_id`, bio, stats
- User tweets: **Do NOT use `Get_User_Tweets`** (rest_id loses precision as a number). Use `Search_Twitter` with query `from:username`, type `Latest` instead.
- Trending topics: `Get_Trends_By_Location`
- Topic research: `Search_Twitter` with topic query
- Following IDs: `Get_User_Following_IDs` → returns up to 5000 IDs by username
- Bulk user lookup: `Get_Users_By_IDs` → returns profiles for comma-separated rest_ids
- Following list (fallback): `Get_User_Followings` → returns following with full profiles by rest_id

### Handling large MCP responses

Twitter search results are often too large for the context window and get saved to a temporary file. When this happens, run the parsing script:

```bash
node ./scripts/parse-tweets.js /path/to/temp-file.json
```

This outputs structured JSON to stdout: `{ "cursor": "...", "tweets": [...] }` with all fields pre-extracted (tweet_id, author_username, full_text, engagement counts, is_reply, is_retweet, media_type, lang, etc.).

### Search Twitter response structure

```
Parsed inner JSON:
├── cursor.bottom          → pagination cursor for next page
├── result.timeline.instructions[0].entries[]
│   ├── tweet entries (entryId: "tweet-XXX")
│   │   └── content.itemContent.tweet_results.result.legacy
│   │       ├── full_text, created_at
│   │       ├── favorite_count, retweet_count, reply_count, quote_count
│   │       ├── in_reply_to_screen_name (if reply)
│   │       └── extended_entities.media[].type (photo/video)
│   └── cursor entries (entryId: "cursor-bottom-0")
│       └── content.value   → same as cursor.bottom
```

See `skills/init.md` Step 2 for the complete parsing reference.
